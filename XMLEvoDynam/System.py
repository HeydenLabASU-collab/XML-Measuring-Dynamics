import numpy as np
import glob
from XMLEvoDynam.MLInputTools import *

# ensure that dimensions are the same between systems

class System:
    """
    A class for generating a System: an object containing the feature sets for each trajectory of interest.
    Meant to be used in conjuction with MLInputTools.

    Attributes:
        system_dir (str): Filename of directory containing data generated by MLInputTools
        systems (list): List of filenames containing names of each system. See MLInputTools for more info.
        group1 (np.array): Array containing indeces of one group of atoms (to compute distances to group 2)
        group2 (np.array): Array containing indeces of a second group of atoms (to compute distances to group 1)
        column_names (np.array): Array containing names (string) of each column (residue pairs)
        keeper_idx (list): Array containing indeces (int) of each column within threshhold
        n_features (int): Number of columns in System
        n_samples (int): Number of rows in System
        input_file (str): Output filename for final System/dataset
        index_file (str): Output filename for final column indeces
        output_file (str): Output filename for dicitonary containing System/dataset info
        cutoff (float/int): Distance cutoff
    """
    def __init__(self, system_dir, systems, group1, group2, cutoff, input_file, index_file, output_file, n_samples, n_features):
        self.system_dir = system_dir
        self.systems = systems
        self.group1 = group1
        self.group2 = group2
        self.column_names = MLInputTools.construct_feature_names(group1, group2)
        self.keeper_idx = []
        self.n_features = n_features
        self.n_samples = n_samples
        self.threshold = lambda v: (np.array(v) < cutoff)
        self.input_file = input_file
        self.index_file = index_file
        self.output_file = output_file
        self.cutoff = cutoff

    def define_columns_within_cutoff(self):
        """
        Generate an array of column indeces where at least one value in the column is less than the defined threshhold.

        Args:
            self (System): System containing information about the systems.

        Returns:
            keeper_idx: Array of column indeces within cutoff distance
        """

        # Take one of the systems and take all columns except for the weights (column -3), the labels (column -2) and the timestep (column -1)
        keeper = np.full(len(np.load(sorted(glob.glob(f"{self.system_dir}/{self.systems[0]}*npy"))[0], allow_pickle=True)[0]), False)
        keeper = keeper[:-3]

        # For each system
        for system in range(len(self.systems)):
            # For each file containing the system name (handle batching)
            for file in sorted(glob.glob(f"{self.system_dir}/{self.systems[system]}*npy")):
                # Load the system/batch
                arr = np.load(file, allow_pickle=True, mmap_mode='r')
                # Iterate over all rows in the array and determine which values (in a single row) are above or below the threshhold value
                for i in range(arr.shape[0]):
                    row = arr[i, :-3]
                    x = self.threshold(row)

                    # if the column contains at LEAST one value below threshhold -> set to 1
                    # otherwise -> set to 0 (feature is outside of range)
                    keeper = np.logical_or(keeper, x)
                    self.n_samples += 1

        # Keeper_idx = list with all column indeces within the cutoff
        keeper_idx = []
        for decision in range(len(keeper)):
            if keeper[decision] == True and str(self.column_names[decision].split("_")[0]) != str(self.column_names[decision].split("_")[1]):
                keeper_idx.append(decision)

        # We want to keep the weights, labels, and timesteps
        keeper_idx.append(len(keeper))
        keeper_idx.append(len(keeper)+1)
        keeper_idx.append(len(keeper)+2)

        # Set the number of features
        self.n_features = len(keeper_idx)
        self.keeper_idx = keeper_idx

        # Save the columns we want to keep such that we can parse feature set later
        np.save(f"{self.index_file}", self.keeper_idx)

        return self.keeper_idx



    def generate_inputSet_within_cutoff(self):
        """
        Generate ONE matrix containing all samples from all systems within the cutoff

        Args:
            self (System): System containing information about the systems.

        Returns:
            dataset: Matrix containing all samples from all systems (wihtin the cutoff)
        """

        # Use memmap
        dataset = np.memmap(f'{self.input_file}', dtype='float32', mode='w+', shape=(self.n_samples, self.n_features))
        end = 0

        # For all systems and all batches (file), load the batch/system and store it in the dataset
        for system in range(len(self.systems)):
            for file in sorted(glob.glob(f"{self.system_dir}/{self.systems[system]}*npy")):
                arr = np.load(file, allow_pickle=True, mmap_mode='r')
                begin = end
                end = begin+len(arr)
                dataset[begin:end] = arr[:, self.keeper_idx]

        # Make sure data is flushed to disk
        dataset.flush()
        return dataset

    def output_system_info(self):
        """
        Generate dictionary containing constructor info

        Args:
            self (System): System containing information about the systems.

        Returns:
            dictionary: dictionary containing constructor info
        """
        dictionary = {'n_samples': self.n_samples,
                      'n_features': self.n_features,
                      'g1': self.group1,
                      'g2': self.group2,
                      'cutoff': self.cutoff,
                      'keeper_idx': self.keeper_idx,
                      'column_names': self.column_names,
                      'system_dir': self.system_dir,
                      'systems': self.systems,
                      'input_file': self.input_file,
                      'index_file': self.index_file,
                      }
        np.save(f'{self.output_file}', dictionary)
        return dictionary

    def load_system_from_dictionary(fIn):
        """
        Load system from dictionary containing constructor info

        Args:
            fIn (str): dictionary filename (self.output_file)

        Returns:
            System: System containing info from the provided dictionary
        """
        MLinfo = np.load(f"{fIn}", allow_pickle=True).item()
        return System(MLinfo['system_dir'], MLinfo['systems'], MLinfo['g1'], MLinfo['g2'], MLinfo['cutoff'], MLinfo['input_file'], MLinfo['index_file'], fIn, MLinfo['n_samples'], MLinfo['n_features'])

